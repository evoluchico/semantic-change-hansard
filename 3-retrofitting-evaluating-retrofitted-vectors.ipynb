{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install researchpy\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport pickle\nimport gensim\nimport matplotlib.pyplot as plt\nfrom joblib import Parallel, delayed\nimport csv\nfrom csv import reader\nfrom scipy import spatial\nimport functools\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\n\nimport imblearn\nfrom imblearn.under_sampling import RandomUnderSampler\n\nimport researchpy as rp\nimport scipy.stats as stats\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session~","metadata":{"execution":{"iopub.status.busy":"2022-06-21T16:59:06.112764Z","iopub.execute_input":"2022-06-21T16:59:06.113211Z","iopub.status.idle":"2022-06-21T16:59:17.015759Z","shell.execute_reply.started":"2022-06-21T16:59:06.113176Z","shell.execute_reply":"2022-06-21T16:59:17.014760Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"# **Importing & Processing Retrofitted vectors**","metadata":{}},{"cell_type":"markdown","source":"**Reading retrofitted out-vector file**","metadata":{}},{"cell_type":"code","source":"%%time\nretrofittedVectorPath = '/kaggle/input/retrofittedvectors/out_vec_file.txt'\nretrofittingFactor = 'party'\n\n#retrofittedVectorPath = '/kaggle/input/retrofittedpartytimevectors/retrofittedPartyTimeVectors.txt'\n#retrofittingFactor = 'party-time'\n\nwith open(retrofittedVectorPath) as f:\n\n    vecs=[]\n    vec=''\n\n    while True:\n        line = f.readline()\n        if not line: \n            break        \n        if(str(list(line)[0]).isalpha()):\n            vec=vec.strip()\n            if(vec!=''):\n                vecs.append(vec)\n            vec = line\n        else:\n            vec+=line\n        \nvecs = [vec.replace('\\n', '')for vec in vecs]\nprint(str(len(vecs))+' Retrofitted vectors obtained')","metadata":{"execution":{"iopub.status.busy":"2022-06-21T16:59:17.017328Z","iopub.execute_input":"2022-06-21T16:59:17.017656Z","iopub.status.idle":"2022-06-21T16:59:17.259074Z","shell.execute_reply.started":"2022-06-21T16:59:17.017623Z","shell.execute_reply":"2022-06-21T16:59:17.258103Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"change = ['exiting', 'seaborne', 'eurotunnel', 'withdrawal', 'departures', 'unicorn', 'remainers', 'exit', 'surrender',\n          'departure', 'triggering', 'stockpiling', 'expulsion', 'blindfold', 'cliff', 'lighter', 'exits', 'triggered',\n          'brexiteer', 'soft', 'plus', 'trigger', 'backroom', 'invoked', 'protesting', 'brexit', 'edge', 'canary', \n          'unicorns', 'withdrawing', 'invoking', 'withdrawn', 'manor', 'brexiteers', 'fanatics', 'postponement', \n          'currencies', 'currency', 'operability', 'operable', 'leavers', 'invoke', 'article', 'eurozone', 'clueless',\n          'surrendered', 'cake', 'red', 'euroscepticism', 'prorogation', 'lining', 'gove', 'norway', 'deflationary',\n          'moribund', 'eurosceptic', 'deutschmark', 'courting', 'deal', 'withdraw', 'dab', 'withdrawals', 'eurosceptics',\n          'surrendering', 'aldous', 'lanarkshire', 'leaving', 'signifying', 'roofs', 'ceded', 'absentia', 'treachery',\n          'dollar', 'canada', 'pragmatist', 'oven', 'ready', 'brexiters', 'control', 'capitulation', 'leave', 'referendum',\n          'agreement', 'prorogue', 'smoothest', 'depreciate', 'managed', 'mutiny', 'overvalued', 'ideologues', 'foreign',\n          'eec', 'war', 'prorogued', 'hannan', 'appease', 'pendolino', 'southbound', 'left', 'line', 'hard', 'bill']\n \nno_change = ['prime', 'even', 'parliament', 'care', 'well', 'constituency', 'tax', 'children',\n             'business', 'report', 'case', 'sure', 'like', 'see', 'state', 'order', 'back', 'new', 'hope', 'local',\n             'secretary', 'public', 'right', 'much', 'say', 'first', 'minister', 'look', 'system', 'whether', \n             'members', 'million', 'good', 'today', 'services', 'clear', 'help', 'time', 'place', 'put', 'last', 'must', 'money', 'one', \n             'way', 'work', 'would', 'think', 'two', 'great', 'could', 'lady', 'us', 'come', 'however', 'may', 'going', 'go',\n             'given', 'year', 'might', 'part', 'get', 'make', 'point', 'committee', 'years', 'also', 'know',\n             'government', 'take', 'house', 'agree', 'member', 'number', 'across', 'made', 'give', 'gentleman', 'important', 'said',\n             'people', 'issue', 'support', 'ensure']\n\nwords_of_interest= change+no_change","metadata":{"execution":{"iopub.status.busy":"2022-06-21T16:59:17.260690Z","iopub.execute_input":"2022-06-21T16:59:17.261339Z","iopub.status.idle":"2022-06-21T16:59:17.276603Z","shell.execute_reply.started":"2022-06-21T16:59:17.261291Z","shell.execute_reply":"2022-06-21T16:59:17.275567Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"**Extracting vectors & mapping to synonym key, checking for dimensions**","metadata":{}},{"cell_type":"code","source":"dictKeyVector = {}\ncount=0\nfor i in range(len(vecs)):\n    \n    vec = vecs[i].strip().split(' ')\n    # Extracting synonym key\n    synKey = vec[0]\n    del(vec[0])\n    vec=[i for i in vec if i!='']\n    \n    if(len(vec)!=300):\n        print('Vector with dimension<300', synKey,len(vec))\n        count=count+1\n    else:\n        vec =[float(v) for v in vec]\n        dictKeyVector[synKey]=vec\n        npVec = np.array(dictKeyVector[synKey])\nprint('Count of vectors with fewer dimensions that we will not consider',count)\ndfRetrofitted = pd.DataFrame({'vectorKey':list(dictKeyVector.keys()), 'vectors':list(dictKeyVector.values())})\ndfRetrofitted.head()\n","metadata":{"execution":{"iopub.status.busy":"2022-06-21T16:59:17.872916Z","iopub.execute_input":"2022-06-21T16:59:17.873654Z","iopub.status.idle":"2022-06-21T16:59:18.185188Z","shell.execute_reply.started":"2022-06-21T16:59:17.873603Z","shell.execute_reply":"2022-06-21T16:59:18.184289Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"dfRetrofitted.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-21T16:59:18.800344Z","iopub.execute_input":"2022-06-21T16:59:18.800810Z","iopub.status.idle":"2022-06-21T16:59:18.808339Z","shell.execute_reply.started":"2022-06-21T16:59:18.800773Z","shell.execute_reply":"2022-06-21T16:59:18.807148Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"**For party based retrofitting\n2071 retrofitted vectors were expected. \n2070 were created. \n55 vectors discarded that had dimensions<300\n2015 vectors left** \n\n\n**For party-time retrofitting - From 1962 input vectors, 1634 retrofitted vectors were received(328 were lost during retrofitting, no reason found yet), \nFurther, 35 vectors have been discarded as the vector dimensions were lost (under 300)\nEventually left with 1599**","metadata":{}},{"cell_type":"markdown","source":"# **Calculating Cosine similarity**","metadata":{}},{"cell_type":"code","source":"# Filtering down words of interest as per those present in our vectors \n# We're amending the computeAvgVec function accordingly\n# As it calculated based on processing from models, and here we're only taking vectors. Hence this check here too.\n\nvectorKeys =list(dfRetrofitted['vectorKey'])\n# Extracting words from vectors keys\nwords_of_interest = list(set([vk.split('-')[0] for vk in vectorKeys]))\nprint(words_of_interest, len(words_of_interest))\n\n# NOW WE ONLY HAVE THOSE WORDS HERE WHICH ARE PRESENT IN THE VECTORS. ","metadata":{"execution":{"iopub.status.busy":"2022-06-21T16:59:23.601858Z","iopub.execute_input":"2022-06-21T16:59:23.602387Z","iopub.status.idle":"2022-06-21T16:59:23.610292Z","shell.execute_reply.started":"2022-06-21T16:59:23.602355Z","shell.execute_reply":"2022-06-21T16:59:23.609458Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"**Functions for cosine similarity computation and to compute the average vector amongst many vectors for a given word**","metadata":{}},{"cell_type":"code","source":"# Different from the avg computation function in our other scripts. This works upon vectors instead of models\ndef computeAvgVec(mKeys, dicto, w, layerSize=300):\n    modelsSum = np.zeros(layerSize)\n    for k in mKeys:\n        vectorPerModel = dicto[k]\n        modelsSum = np.add(modelsSum, vectorPerModel)\n    avgEmbedding =np.divide(modelsSum, len(mKeys))\n    return avgEmbedding\n\ndef cosine_similarity(vec1, vec2):\n  sc = 1-spatial.distance.cosine(vec1, vec2)\n  return sc\n\ncosine_similarity_df = pd.DataFrame(columns = ('Word', 'Cosine_similarity'))","metadata":{"execution":{"iopub.status.busy":"2022-06-21T16:59:25.482142Z","iopub.execute_input":"2022-06-21T16:59:25.482693Z","iopub.status.idle":"2022-06-21T16:59:25.491724Z","shell.execute_reply.started":"2022-06-21T16:59:25.482661Z","shell.execute_reply":"2022-06-21T16:59:25.490672Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"**Compute cosine similarity between avg T1 and T2 vectors**","metadata":{}},{"cell_type":"code","source":"%%time\n\nt1Keys = [t for t in list(dictKeyVector.keys()) if 't1' in t]\nt2Keys = [t for t in list(dictKeyVector.keys()) if 't2' in t]\nsims= []\n\n# Compute average of word in T1 and in T2 and store average vectors and cosine difference   \nfor word in words_of_interest:\n        \n        #Provide a list of keys to average computation model for it to\n        #compute average vector amongst these models\n        wordT1Keys = [k for k in t1Keys if k.split('-')[0]==word]\n        wordT2Keys = [k for k in t2Keys if k.split('-')[0]==word]\n        \n        #Since here the key itself contains the word we're not simply sending T1 keys but sending word-wise key\n        avgVecT1 = computeAvgVec(wordT1Keys, dictKeyVector, word)\n        avgVecT2 = computeAvgVec(wordT2Keys, dictKeyVector, word)\n        \n        if(avgVecT1.shape == avgVecT2.shape):\n            # Cos similarity between averages\n            cosSimilarity = cosine_similarity(avgVecT1, avgVecT2)\n            sims.append(cosSimilarity)\n        else:\n            print('Word not found')\ncosine_similarity_df['Word']=words_of_interest\ncosine_similarity_df['Cosine_similarity']=sims\n\n'''\ncosine_similarity_df_sorted = cosine_similarity_df.sort_values(by='Cosine_similarity', ascending=True)\ncosine_similarity_df_sorted'''\n\n#Assigning change and no-change labels as initially expected\ncosine_similarity_df['semanticDifference']=['default' for i in range(cosine_similarity_df.shape[0])]\ncosine_similarity_df.loc[cosine_similarity_df['Word'].isin(change), 'semanticDifference'] = 'change' \ncosine_similarity_df.loc[cosine_similarity_df['Word'].isin(no_change), 'semanticDifference'] = 'no_change' \ncosine_similarity_df.sort_values(by='Cosine_similarity').head(10)","metadata":{"execution":{"iopub.status.busy":"2022-06-21T16:59:26.992102Z","iopub.execute_input":"2022-06-21T16:59:26.992523Z","iopub.status.idle":"2022-06-21T16:59:27.175849Z","shell.execute_reply.started":"2022-06-21T16:59:26.992490Z","shell.execute_reply":"2022-06-21T16:59:27.174681Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"# **LOGISTIC REGRESSION**","metadata":{}},{"cell_type":"markdown","source":"**Evaluate the performance of retrofitted vectors**","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n","metadata":{"execution":{"iopub.status.busy":"2022-06-21T16:59:28.522125Z","iopub.execute_input":"2022-06-21T16:59:28.522549Z","iopub.status.idle":"2022-06-21T16:59:28.527398Z","shell.execute_reply.started":"2022-06-21T16:59:28.522515Z","shell.execute_reply":"2022-06-21T16:59:28.526162Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"X = cosine_similarity_df['Cosine_similarity'].values.reshape(-1,1)\ny = cosine_similarity_df['semanticDifference']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=22)\n\nundersample = RandomUnderSampler(sampling_strategy=1.0)\n\nX_over, y_over = undersample.fit_resample(X, y)\nX=X_over\ny=y_over\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2)\n\nlogreg = LogisticRegression()\nkf = logreg.fit(X_train, y_train)\n\ny_pred = logreg.predict(X_test)\n\nprint('Y value counts',y.value_counts(),'\\n')\nprint('Y train value counts', y_train.value_counts())","metadata":{"execution":{"iopub.status.busy":"2022-06-21T16:59:29.546787Z","iopub.execute_input":"2022-06-21T16:59:29.547181Z","iopub.status.idle":"2022-06-21T16:59:29.570597Z","shell.execute_reply.started":"2022-06-21T16:59:29.547147Z","shell.execute_reply":"2022-06-21T16:59:29.569344Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"#scoring = {}\nprint(accuracy_score)\n#if (retrofittingFactor=='party'):\n    \nscoring = {'accuracy' : make_scorer(accuracy_score), \n               'precision' : make_scorer(precision_score,pos_label='change'),\n               'recall' : make_scorer(recall_score,pos_label='change'), \n               'f1_score' : make_scorer(f1_score,pos_label='change')}\n\nscores = cross_validate(kf, X, y, cv=10, scoring=scoring,error_score='raise')\n\nprint('Accuracy', scores['test_accuracy'].mean())\nprint('Precision', scores['test_precision'].mean())\nprint('Recall', scores['test_recall'].mean())\nprint('F1 Score', scores['test_f1_score'].mean())\n","metadata":{"execution":{"iopub.status.busy":"2022-06-21T16:59:30.662005Z","iopub.execute_input":"2022-06-21T16:59:30.662439Z","iopub.status.idle":"2022-06-21T16:59:30.753154Z","shell.execute_reply.started":"2022-06-21T16:59:30.662408Z","shell.execute_reply":"2022-06-21T16:59:30.751997Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"cf_matrix = confusion_matrix(y_test, y_pred)\n\nax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n\nax.set_title('Confusion Matrix for vectors retrofitted on the basis of same party \\n\\n');\nax.set_xlabel('\\nPredicted Values')\nax.set_ylabel('Actual Values ');\n\nax.xaxis.set_ticklabels(['change','no_change'])\nax.yaxis.set_ticklabels(['change','no_change'])\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-21T16:59:31.962483Z","iopub.execute_input":"2022-06-21T16:59:31.962891Z","iopub.status.idle":"2022-06-21T16:59:32.219626Z","shell.execute_reply.started":"2022-06-21T16:59:31.962858Z","shell.execute_reply":"2022-06-21T16:59:32.218542Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# T Test \n\nsummary, results = rp.ttest(group1= cosine_similarity_df['Cosine_similarity'][cosine_similarity_df['semanticDifference'] == 'change'], group1_name= \"change\",\n                            group2= cosine_similarity_df['Cosine_similarity'][cosine_similarity_df['semanticDifference'] == 'no_change'], group2_name= \"no_change\")\nprint(summary)","metadata":{"execution":{"iopub.status.busy":"2022-06-21T16:59:33.514511Z","iopub.execute_input":"2022-06-21T16:59:33.514978Z","iopub.status.idle":"2022-06-21T16:59:33.547014Z","shell.execute_reply.started":"2022-06-21T16:59:33.514942Z","shell.execute_reply":"2022-06-21T16:59:33.545757Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"accuracy, precision, recall, f1_score = [], [], [], []\nretrofittingBasis = [retrofittingFactor]","metadata":{"execution":{"iopub.status.busy":"2022-06-21T16:59:35.527957Z","iopub.execute_input":"2022-06-21T16:59:35.528435Z","iopub.status.idle":"2022-06-21T16:59:35.534346Z","shell.execute_reply.started":"2022-06-21T16:59:35.528398Z","shell.execute_reply":"2022-06-21T16:59:35.533097Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"#scoresDf = pd.DataFrame(columns= ['retrofittingBasis','Accuracy','Precision','Recall','F1Score'])\n#scoresDf.append(['party', scores['test_accuracy'].mean(), scores['test_precision'].mean(),scores['test_recall'].mean(), scores['test_f1_score'].mean()],axis=1)\naccuracy.append(scores['test_accuracy'].mean())\nprecision.append(scores['test_precision'].mean())\nrecall.append(scores['test_recall'].mean())\nf1_score.append(scores['test_f1_score'].mean())","metadata":{"execution":{"iopub.status.busy":"2022-06-21T16:59:39.304672Z","iopub.execute_input":"2022-06-21T16:59:39.305080Z","iopub.status.idle":"2022-06-21T16:59:39.312109Z","shell.execute_reply.started":"2022-06-21T16:59:39.305048Z","shell.execute_reply":"2022-06-21T16:59:39.310724Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"'''scoresDict = {'retrofittingBasis': 'party','Accuracy':[scores['test_accuracy'].mean()],'Precision':scores['test_precision'].mean(),'Recall':scores['test_recall'].mean(),'F1Score':scores['test_f1_score'].mean()}\nscoresDf = pd.DataFrame(scoresDict)\n\npd.concat([scoresDf,np.series(['party', scores['test_accuracy'].mean(), scores['test_precision'].mean(),scores['test_recall'].mean(), scores['test_f1_score'].mean()]) ])'''","metadata":{"execution":{"iopub.status.busy":"2022-06-21T16:48:52.242668Z","iopub.execute_input":"2022-06-21T16:48:52.243101Z","iopub.status.idle":"2022-06-21T16:48:52.249256Z","shell.execute_reply.started":"2022-06-21T16:48:52.243067Z","shell.execute_reply":"2022-06-21T16:48:52.248299Z"},"trusted":true},"execution_count":124,"outputs":[]},{"cell_type":"code","source":"scoresDict = {'retrofittingBasis': retrofittingBasis,'Accuracy':accuracy,'Precision':precision,'Recall':recall,'F1Score':f1_score}\nif(retrofittingFactor=='party'):\n    scoresDf = pd.DataFrame(scoresDict)\nelse:\n    scoresDf = pd.concat([scoresDf, pd.DataFrame(scoresDict)])\nscoresDf","metadata":{"execution":{"iopub.status.busy":"2022-06-21T16:59:50.923409Z","iopub.execute_input":"2022-06-21T16:59:50.923926Z","iopub.status.idle":"2022-06-21T16:59:50.943043Z","shell.execute_reply.started":"2022-06-21T16:59:50.923888Z","shell.execute_reply":"2022-06-21T16:59:50.941795Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"#Just in case\n#scoresDf.to_pickle('./partyScore.pkl')","metadata":{"execution":{"iopub.status.busy":"2022-06-21T17:00:03.255024Z","iopub.execute_input":"2022-06-21T17:00:03.255945Z","iopub.status.idle":"2022-06-21T17:00:03.260211Z","shell.execute_reply.started":"2022-06-21T17:00:03.255902Z","shell.execute_reply":"2022-06-21T17:00:03.259155Z"},"trusted":true},"execution_count":43,"outputs":[]}]}